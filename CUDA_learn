#2022.07.05
参考链接：
        1.  https://zhuanlan.zhihu.com/p/34587739，CUDA编程入门极简教程。
        2. https://blog.csdn.net/u013025612/article/details/47039437，左移（1<<20）。
        3. https://developer.nvidia.com/blog/even-easier-introduction-cuda/，An Even Easier Introduction to CUDA。
        
1. cuda的基本概念
        1.1. 一般说的GPU运算指的是基于CPU+GPU的异构计算。在异构计算中，GPU与CPU需要通过PCIe总线连接在一起来工作，CPU所在位置称为主机端（host），
                GPU所在位置称为设备端（device）。
        1.2. GPU运算核心多，适合大规模并行计算，但每个核心的性能较弱。
                CPU运算核心相对较少，但每个核心性能较强，可以实现复杂的逻辑运算。
                综合而言，两者能力互补，CPU负责处理逻辑复杂的串行程序，GPU负责重点处理数据密集型的并行计算程序。
        1.3. CUDA是NVIDIA公司所开发的GPU编程模型，它提供了GPU编程的简易接口，基于CUDA编程可以构建基于GPU计算的应用程序。CUDA提供了对其它编程语
                言的支持，如C/C++，Python，Fortran等语言。
        1.4. 在CUDA程序中，host和device是两个重要的概念。一般而言，host指代CPU及其内存，device指代GPU及其内存。CUDA程序中既包含host程序，又包含
                device程序，它们分别在CPU和GPU上运行。同时，host与device之间可以进行通信，这样它们之间可以进行数据拷贝。典型的CUDA程序的执行流程如下：
                - 分配host内存，并进行数据初始化；
                - 分配device内存，并从host中将数据拷贝到device上；
                - 调用CUDA的核函数（kernel）在device上完成指定的运算；
                - 将device上的运算结果拷贝到host上；
                - 释放device和host上分配的内存。
        1.5. kernel是CUDA中一个重要的概念，kernel是在device上线程中并行执行的函数，核函数用__global__符号声明，在调用时需要用<<<grid, block>>>来指定
                kernel要执行的线程数量。在CUDA中，每一个线程都要执行核函数，并且每个线程会分配一个唯一的线程号thread ID，这个ID值可以通过核函数的内置变
                量threadIdx来获得。
        1.6. 由于GPU实际上是异构模型，所以需要区分host和device上的代码，在CUDA中是通过函数类型限定词开区别host和device上的函数，主要的三个函数类型
                限定词如下：
                - __global__：在device上执行，从host中调用（一些特定的GPU也可以从device上调用），返回类型必须是void，不支持可变参数参数，不能成为类成员
                  函数。注意用__global__定义的kernel是异步的，这意味着host不会等待kernel执行完就执行下一步。
                - __device__：在device上执行，单仅可以从device中调用，不可以和__global__同时用。
                - __host__：在host上执行，仅可以从host上调用，一般省略不写，不可以和__global__同时用，但可和__device__，此时函数会在device和host都编译。                                        
        1.7. 软件概念层面：
                        -   一个kernel所启动的所有线程称为一个网格（grid），一个grid中可以包含一个或多个线程块（block），一个block中包含很多个线程。
                硬件概念层面：
                        -   一个Device包含一个或多个Streaming Multiprocessor（SM），一个SM包含一个或多个CUDA Core（SM的执行单元是线程束，一个线程束包含32个线
                            程，因此block的数量一般设置为32的的倍数）。
                        -   SM的核心组件包括CUDA核心，共享内存，寄存器等，SM可以并发地执行数百个线程，并发能力就取决于SM所拥有的资源数。
                        -   当一个kernel被执行时，它的gird中的线程块被分配到SM上，一个线程块只能在一个SM上被调度。SM一般可以调度多个线程块，这要看SM本身的能力。
                        -   SM采用的是SIMT (Single-Instruction, Multiple-Thread，单指令多线程)架构，基本的执行单元是线程束（warps)，线程束包含32个线程，这些线程同时
                            执行相同的指令，但是每个线程都包含自己的指令地址计数器和寄存器状态，也有自己独立的执行路径。
                总之，就是网格和线程块只是逻辑划分，一个kernel的所有线程其实在物理层是不一定同时并发的。所以kernel的grid和block的配置不同，性能会出现差异，这
                点是要特别注意的。
        1.8. grid和block都是定义为dim3类型的变量，dim3可以看成是包含三个无符号整数（x，y，z）成员的结构体变量，在定义时，缺省值初始化为1。因此grid和block
                可以灵活地定义为1-dim，2-dim以及3-dim结构。kernel在调用时也必须通过执行配置<<<grid, block>>>来指定kernel所使用的线程数及结构。
                例子：
                        dim3 grid(3, 2);
                        dim3 block(5, 3);
                        kernel_fun<<< grid, block >>>(prams...);
        1.9. 一个线程需要两个内置的坐标变量（blockIdx，threadIdx）来唯一标识，它们都是dim3类型变量，其中blockIdx指明线程所在grid中的位置，而threaIdx指明线
               程所在block中的位置。
               blockDim来获取线程块各个维度的大小。
               另外线程还有内置变量gridDim，用于获得网格块各个维度的大小。
        1.10. CUDA的内存模型，如下图所示。可以看到，每个线程有自己的私有本地内存（Local Memory），而每个线程块有包含共享内存（Shared Memory）,可以被线
                程块中所有线程共享，其生命周期与线程块一致。此外，所有的线程都可以访问全局内存（Global Memory）。还可以访问一些只读内存块：常量内存（Constant Memory）
                和纹理内存（Texture Memory）。内存结构涉及到程序优化。
2. cuda基本程序学习
        2.1. 加法
                // 两个向量加法kernel，grid和block均为一维
                __global__ void add(float* x, float * y, float* z, int n)
                {
                    // 获取全局索引
                    int index = threadIdx.x + blockIdx.x * blockDim.x;
                   // 步长
                    int stride = blockDim.x * gridDim.x;
                    for (int i = index; i < n; i += stride)
                    {
                        z[i] = x[i] + y[i];
                    }
                }
                int main()
                {
                    int N = 1 << 20;
                    int nBytes = N * sizeof(float);

                    // 申请托管内存
                    float *x, *y, *z;
                    cudaMallocManaged((void**)&x, nBytes);
                    cudaMallocManaged((void**)&y, nBytes);
                    cudaMallocManaged((void**)&z, nBytes);

                    // 初始化数据
                    for (int i = 0; i < N; ++i)
                    {
                        x[i] = 10.0;
                        y[i] = 20.0;
                    }

                    // 定义kernel的执行配置
                    dim3 blockSize(256);
                    dim3 gridSize((N + blockSize.x - 1) / blockSize.x);
                    // 执行kernel
                    add << < gridSize, blockSize >> >(x, y, z, N);

                    // 同步device 保证结果能正确访问
                    cudaDeviceSynchronize();
                    // 检查执行结果
                    float maxError = 0.0;
                    for (int i = 0; i < N; i++)
                        maxError = fmax(maxError, fabs(z[i] - 30.0));
                    std::cout << "最大误差: " << maxError << std::endl;

                    // 释放内存
                    cudaFree(x);
                    cudaFree(y);
                    cudaFree(z);

                    return 0;
                }
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
#2022.07.06
参考链接：
        1. https://zhuanlan.zhihu.com/p/360897341，CUDA 编程小练习（一）。
        2. https://medium.com/@iphoenix179/running-cuda-c-c-in-jupyter-or-how-to-run-nvcc-in-google-colab-663d33f53772，Running CUDA C/C++ 
             in Jupyter or how to run nvcc in Google CoLab。
        3. https://developer.nvidia.com/blog/even-easier-introduction-cuda/， An Even Easier Introduction to CUDA。
        
1. cuda环境搭建
    由于没有GPU，根据 https://zhuanlan.zhihu.com/p/360897341 中的建议采用colab进行cuda基本的程序练习。
    1.1. 打开colab，建立一个新的笔记本（然后安需要修改笔记本名字）。
    1.2. 点击代码执行程序（Runtimes）-> 选择更改运行时类型（change runtime type）->  硬件加速器（Hardware accelerator）选择GPU。
    1.3. 然后，需要安装juputer的一个插件以支持NVCC的源码编译。此部分内容与原链接中描述的稍有不同，因为在我的尝试中，原文的代码
            无法访问github（网页可以的登陆，初步排除vpn的问题）。
            - 原代码：
                    !pip install git+git://github.com/depctg/nvcc4jupyter.git
                    %load_ext nvcc_plugin
                    !nvcc --version
            - 修改过的可运行代码：
                    !pip install git+https://github.com/depctg/nvcc4jupyter.git          //将原来的"git+git:" 改为了"git+https:"
                    %load_ext nvcc_plugin
                    !nvcc --version
    1.4. 测试例程（此程序也来自与此链接）
            %%cu                                                                                                                             //当程序的语言是c/c++时，需要告诉interpreter，此处的%cu就是这个作用。
            #include <stdio.h>
            __global__ void cuda_hello()
            {
                    printf("Hello world from GPU!\n");
            }
            
            int main()
            {
                    cuda_hello<<<1,1>>>();
                    cudaDeviceSynchronize();                                                                           //由于__global__形式的函数是异步的，因此需要同步一下（除此之外需要这个函数才可以将printf显示到屏幕上）。
                    return 0;
            }
    1.5.
    1.6. 
    1.7. 
    1.8. 
    1.9. 
    1.10. 
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
